{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c7833d",
   "metadata": {},
   "source": [
    "<h4>Import and setup</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fb64454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "from surprise import BaselineOnly, Dataset, Reader, SVD, NMF, SVDpp, accuracy, PredictionImpossible, KNNWithMeans, KNNBasic\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV, PredefinedKFold\n",
    "from surprise.model_selection.split import LeaveOneOut\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f52e7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/1792210709.py:9: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/1792210709.py:9: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x33b2263b0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', \n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "column_names = [\"item\",\"title\",\"genres\",\"movie_name\",\"movie_year\",\"(no genres listed)\",\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"IMAX\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\",\"user\",\"rating\",\"rating_timestamp\",\"rating_year\",\"rating_month\",\"rating_season,tag\",\"tag_timestamp\",\"cleaned_tag\",\"tag_length\",\"tag_year\"]\n",
    "\n",
    "data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "ratings = data[['user', 'item', 'rating']]\n",
    "ratings = ratings.iloc[1:]\n",
    "ratings[\"rating\"] = ratings[\"rating\"].astype(float)\n",
    "\n",
    "custom_data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "print(custom_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5f35a",
   "metadata": {},
   "source": [
    "<h4>Train Test Split</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "165926d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "trainset, testset = train_test_split(custom_data, test_size=0.2)\n",
    "\n",
    "# Convert trainset to dataframe (for content-based model)\n",
    "train_df = pd.DataFrame(trainset.build_testset(), columns=['user', 'item', 'rating'])\n",
    "test_df = pd.DataFrame(testset, columns=['user', 'item', 'rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c6478",
   "metadata": {},
   "source": [
    "<h4>Get eligible users</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f896781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter users with >= 5 test ratings\n",
    "test_user_counts = test_df['user'].value_counts()\n",
    "eligible_users = test_user_counts[test_user_counts >= 5].index.tolist()\n",
    "\n",
    "# Different number of known ratings to test\n",
    "known_ratings_list = [5]\n",
    "# known_ratings_list = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918e97d",
   "metadata": {},
   "source": [
    "<h4>Grid Search CV with SVD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccb2746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_param_grid = {\n",
    "#     \"n_factors\":[50, 100],\n",
    "#     \"lr_all\":[0.002, 0.005],\n",
    "#     \"reg_all\": [0.02, 0.1]\n",
    "# }\n",
    "\n",
    "# svd_grid = GridSearchCV(SVD, svd_param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "# svd_grid.fit(custom_data)\n",
    "\n",
    "# # Train the SVD model\n",
    "# svd = svd_grid.best_estimator[\"rmse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b63f6",
   "metadata": {},
   "source": [
    "<h4>Movie data setup</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1e7644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2531497710.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies[genre_cols] = movies[genre_cols].astype(bool)\n",
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2531497710.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies[genre_cols] = movies[genre_cols].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [item, title, Action, Adventure, Animation, Children, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movies = data[['item', 'title'] + genre_cols]\n",
    "movies[genre_cols] = movies[genre_cols].astype(bool)\n",
    "movies[genre_cols] = movies[genre_cols].astype(int)\n",
    "# movies = movies.rename(columns={'movieId': 'item'})\n",
    "movies = movies.drop_duplicates(subset='item', keep='first')\n",
    "\n",
    "# Check for duplicate 'item' IDs\n",
    "duplicate_items = movies[movies.duplicated(subset='item', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(duplicate_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66355a72",
   "metadata": {},
   "source": [
    "<h4>Building user profiles for content-based recommender</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7f42c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of item_profiles: (15318, 18)\n",
      "No duplicate item_ids found in item_profiles.\n"
     ]
    }
   ],
   "source": [
    "# 4. Build User Profiles for Content-Based Recommender\n",
    "# Step 4.1: Merge ratings and movie genres\n",
    "train_merged = pd.merge(train_df[['user', 'item']], data, on=['user', 'item'], how='inner')\n",
    "train_merged = train_merged[['user', 'item', 'rating', \"title\"]+genre_cols]\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(bool)\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(int)\n",
    "\n",
    "# Step 4.2: Create user profiles based on genres\n",
    "user_profiles = train_merged.groupby('user')[genre_cols].mean()\n",
    "\n",
    "# Normalize user profiles (optional, helps with cosine similarity)\n",
    "user_profiles = user_profiles.div(user_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# 5. Build Item Profile Matrix\n",
    "item_profiles = movies.set_index('item')[genre_cols]\n",
    "item_profiles = item_profiles.div(item_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "# Count the number of ratings per user\n",
    "user_rating_counts = train_df['user'].value_counts()\n",
    "\n",
    "# Debugging: Check the shape of item_profiles\n",
    "print(f\"Shape of item_profiles: {item_profiles.shape}\")\n",
    "\n",
    "# Check for duplicate item_ids in item_profiles\n",
    "if item_profiles.index.duplicated().any():\n",
    "    print(\"Duplicate item_ids found in item_profiles.\")\n",
    "else:\n",
    "    print(\"No duplicate item_ids found in item_profiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80409e",
   "metadata": {},
   "source": [
    "<h4>Content based prediction function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bee643c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make Predictions\n",
    "# Helper function: Content-based rating prediction\n",
    "def predict_content_based(user_id, item_id):\n",
    "    try:\n",
    "        # Get the user profile and item profile\n",
    "        user_vector = user_profiles.loc[user_id]\n",
    "        \n",
    "        # Ensure item_id is a valid index in item_profiles\n",
    "        if item_id in item_profiles.index:\n",
    "            item_vector = item_profiles.loc[item_id]\n",
    "            if item_vector.ndim == 1:\n",
    "                # Cosine similarity between user and item vectors\n",
    "                similarity = np.dot(user_vector, item_vector) / (np.linalg.norm(user_vector) * np.linalg.norm(item_vector))\n",
    "                # Scale similarity to rating scale (1-5)\n",
    "                # Since similarity can be from -1 to 1, we adjust it:\n",
    "                predicted_rating = 2.5 + 2.5 * similarity  # Center at 2.5, range approx 1-5\n",
    "                return np.clip(predicted_rating, 1.0, 5.0)\n",
    "            else:\n",
    "                print(f\"item_vector for item {item_id} is not 1-dimensional.\")\n",
    "                return train_df['rating'].mean()\n",
    "        else:\n",
    "            print(f\"Item {item_id} not found in item_profiles.\")\n",
    "            return train_df['rating'].mean()\n",
    "    except KeyError:\n",
    "        # If user or item not found (cold start for genre), return global mean\n",
    "        return train_df['rating'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111f384",
   "metadata": {},
   "source": [
    "<h4>Basic Weighted Hybrid Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f27053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def basic_weighted_hybrid_predict(user_id, item_id, algo):\n",
    "    colab_weight=0.5\n",
    "    content_weight=0.5\n",
    "\n",
    "    # algo prediction\n",
    "    try:\n",
    "        colab_pred = algo.predict(user_id, item_id).est\n",
    "    except:\n",
    "        colab_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (colab_weight * colab_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f0c0e",
   "metadata": {},
   "source": [
    "<h1>Switching Hybrid Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17b0b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def switiching_weighted_hybrid_predict(user_id, item_id, algo):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        colab_weight = 0.0\n",
    "        content_weight = 1.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        colab_weight = 0.2\n",
    "        content_weight = 0.8\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        colab_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    elif 6 <= num_ratings <= 15:\n",
    "        colab_weight = 0.8\n",
    "        content_weight = 0.2\n",
    "    else:\n",
    "        colab_weight = 1\n",
    "        content_weight = 0\n",
    "    \n",
    "    # algo prediction\n",
    "    try:\n",
    "        colab_pred = algo.predict(user_id, item_id).est\n",
    "    except:\n",
    "        colab_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (colab_weight * colab_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dd97d",
   "metadata": {},
   "source": [
    "<h1>Ensemble switching hybrid (KNN and SVD)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "534b0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def ensemble_weighted_hybrid_predict(user_id, item_id, mf_algo, neighbour_algo):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        mf_weight = 0.0\n",
    "        neighbour_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        mf_weight = 0.2\n",
    "        neighbour_weight = 0.5\n",
    "        content_weight = 0.3\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        mf_weight = 0.5\n",
    "        neighbour_weight = 0.3\n",
    "        content_weight = 0.2\n",
    "    elif 10 <= num_ratings <= 15:\n",
    "        mf_weight = 0.7\n",
    "        neighbour_weight = 0.2\n",
    "        content_weight = 0.1\n",
    "    else:\n",
    "        mf_weight = 1\n",
    "        neighbour_weight = 0\n",
    "        content_weight = 0\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        mf_pred = mf_algo.predict(user_id, item_id).est\n",
    "    except:\n",
    "        mf_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # KNN prediction\n",
    "    try:\n",
    "        neighbour_pred = neighbour_algo.predict(user_id, item_id).est\n",
    "    except:\n",
    "        neighbour_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (mf_weight * mf_pred) + (neighbour_weight * neighbour_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8e30a",
   "metadata": {},
   "source": [
    "<h4>NDCG@K Calculation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "331e056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_k(ranked_list, ground_truth, k=10):\n",
    "    if len(ranked_list) > k:\n",
    "        ranked_list = ranked_list[:k]\n",
    "    \n",
    "    if not ground_truth:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(ranked_list):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1.0 / np.log2(i + 2)  # +2 because index starts from 0\n",
    "    \n",
    "    # Calculate IDCG\n",
    "    idcg = 0.0\n",
    "    ideal_relevant = min(len(ground_truth), k)\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_relevant))\n",
    "    \n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89a44",
   "metadata": {},
   "source": [
    "<h4>Function to run hybrid models with cold start data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44c94d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hybrid_models(hybrid_functions, hybrid_names, algo, train_df, test_df, eligible_users, known_ratings_list, k=10):\n",
    "    all_results = []\n",
    "\n",
    "    # Prepare the test set for Surprise\n",
    "    final_testset = [tuple(x) for x in test_df.to_numpy()]\n",
    "\n",
    "    # Calculate the set of all movies\n",
    "    all_movies = set(train_df['item'].unique())\n",
    "\n",
    "    # Calculate the set of seen movies for each user\n",
    "    seen_movies_dict = {user: set(train_df[train_df['user'] == user]['item']) for user in eligible_users}\n",
    "\n",
    "    # Calculate the set of unseen movies for each user\n",
    "    unseen_movies_dict = {user: list(all_movies - seen_movies_dict[user]) for user in eligible_users}\n",
    "\n",
    "    for hybrid_func, hybrid_name in zip(hybrid_functions, hybrid_names):\n",
    "        rmse_results = []\n",
    "        mae_results = []\n",
    "        mse_results = []\n",
    "        ndcg_results = []\n",
    "\n",
    "        # Iterate over each number of known ratings\n",
    "        for known_ratings in known_ratings_list:\n",
    "            print(f\"Processing for {known_ratings} known ratings per user with {hybrid_name}...\")\n",
    "            \n",
    "            # Step 3: Reduce training data to 'known_ratings' ratings per user for these test users (simulate cold start)\n",
    "            limited_train_rows = []\n",
    "            for user in eligible_users:\n",
    "                user_ratings = train_df[train_df['user'] == user]\n",
    "                if len(user_ratings) > known_ratings:\n",
    "                    sampled = user_ratings.sample(known_ratings, random_state=42)\n",
    "                else:\n",
    "                    sampled = user_ratings\n",
    "                limited_train_rows.append(sampled)\n",
    "\n",
    "            # Step 4: Add all training data from non-eligible users (normal users)\n",
    "            non_eligible_users_df = train_df[~train_df['user'].isin(eligible_users)]\n",
    "            cold_start_train_df = pd.concat(limited_train_rows + [non_eligible_users_df], ignore_index=True)\n",
    "\n",
    "            # Build training set for Surprise\n",
    "            reader = Reader(rating_scale=(train_df['rating'].min(), train_df['rating'].max()))\n",
    "            cold_start_data = Dataset.load_from_df(cold_start_train_df[['user', 'item', 'rating']], reader)\n",
    "            cold_start_trainset = cold_start_data.build_full_trainset()\n",
    "\n",
    "            # Train the SVD model (if needed)\n",
    "            algo.fit(cold_start_trainset)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            hybrid_predictions = []\n",
    "            true_ratings = []\n",
    "            ndcg_scores = []\n",
    "\n",
    "            for (user, item, true_r) in final_testset:\n",
    "                pred = hybrid_func(user, item, algo)\n",
    "                if not np.isnan(pred) and not np.isnan(true_r):\n",
    "                    hybrid_predictions.append(pred)\n",
    "                    true_ratings.append(true_r)\n",
    "                    \n",
    "                    # Calculate NDCG@K for each user\n",
    "                    user_test_ratings = test_df[test_df['user'] == user]\n",
    "                    true_liked_movies = user_test_ratings[user_test_ratings['rating'] >= 4]['item'].tolist()\n",
    "                    \n",
    "                    if true_liked_movies:\n",
    "                        predictions = [(movie_id, hybrid_func(user, movie_id, algo)) for movie_id in unseen_movies_dict[user]]\n",
    "                        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                        top_k_movies = [movie_id for movie_id, _ in predictions[:k]]\n",
    "                        \n",
    "                        ndcg = calculate_ndcg_at_k(top_k_movies, true_liked_movies, k=k)\n",
    "                        ndcg_scores.append(ndcg)\n",
    "\n",
    "            # Evaluate\n",
    "            rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "            mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "            mse = mean_squared_error(true_ratings, hybrid_predictions)\n",
    "            average_ndcg = np.mean(ndcg_scores)\n",
    "            \n",
    "            rmse_results.append((known_ratings, rmse))\n",
    "            mae_results.append((known_ratings, mae))\n",
    "            mse_results.append((known_ratings, mse))\n",
    "            ndcg_results.append((known_ratings, average_ndcg))\n",
    "            \n",
    "            print(f\"RMSE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {rmse}\")\n",
    "            print(f\"MAE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {mae}\")\n",
    "            print(f\"MSE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {mse}\")\n",
    "            print(f\"NDCG@{k} on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {average_ndcg}\")\n",
    "\n",
    "        # Create a DataFrame to store the results for the current model\n",
    "        results_df = pd.DataFrame({\n",
    "            'Model': hybrid_name,\n",
    "            'Known Ratings': [r[0] for r in rmse_results],\n",
    "            'RMSE': [r[1] for r in rmse_results],\n",
    "            'MAE': [r[1] for r in mae_results],\n",
    "            'MSE': [r[1] for r in mse_results],\n",
    "            'NDCG@K': [r[1] for r in ndcg_results]\n",
    "        })\n",
    "\n",
    "        # Append the results to the all_results list\n",
    "        all_results.append(results_df)\n",
    "\n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    return final_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "604ceac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_hybrid_models(hybrid_functions, hybrid_names, algo, algo_2, train_df, test_df, eligible_users, known_ratings_list, k=10):\n",
    "    all_results = []\n",
    "\n",
    "    # Prepare the test set for Surprise\n",
    "    final_testset = [tuple(x) for x in test_df.to_numpy()]\n",
    "\n",
    "    # Calculate the set of all movies\n",
    "    all_movies = set(train_df['item'].unique())\n",
    "\n",
    "    # Calculate the set of seen movies for each user\n",
    "    seen_movies_dict = {user: set(train_df[train_df['user'] == user]['item']) for user in eligible_users}\n",
    "\n",
    "    # Calculate the set of unseen movies for each user\n",
    "    unseen_movies_dict = {user: list(all_movies - seen_movies_dict[user]) for user in eligible_users}\n",
    "\n",
    "    for hybrid_func, hybrid_name in zip(hybrid_functions, hybrid_names):\n",
    "        rmse_results = []\n",
    "        mae_results = []\n",
    "        mse_results = []\n",
    "        ndcg_results = []\n",
    "\n",
    "        # Iterate over each number of known ratings\n",
    "        for known_ratings in known_ratings_list:\n",
    "            print(f\"Processing for {known_ratings} known ratings per user with {hybrid_name}...\")\n",
    "            \n",
    "            # Step 3: Reduce training data to 'known_ratings' ratings per user for these test users (simulate cold start)\n",
    "            limited_train_rows = []\n",
    "            for user in eligible_users:\n",
    "                user_ratings = train_df[train_df['user'] == user]\n",
    "                if len(user_ratings) > known_ratings:\n",
    "                    sampled = user_ratings.sample(known_ratings, random_state=42)\n",
    "                else:\n",
    "                    sampled = user_ratings\n",
    "                limited_train_rows.append(sampled)\n",
    "\n",
    "            # Step 4: Add all training data from non-eligible users (normal users)\n",
    "            non_eligible_users_df = train_df[~train_df['user'].isin(eligible_users)]\n",
    "            cold_start_train_df = pd.concat(limited_train_rows + [non_eligible_users_df], ignore_index=True)\n",
    "\n",
    "            # Build training set for Surprise\n",
    "            reader = Reader(rating_scale=(train_df['rating'].min(), train_df['rating'].max()))\n",
    "            cold_start_data = Dataset.load_from_df(cold_start_train_df[['user', 'item', 'rating']], reader)\n",
    "            cold_start_trainset = cold_start_data.build_full_trainset()\n",
    "\n",
    "            # Train the SVD model (if needed)\n",
    "            algo.fit(cold_start_trainset)\n",
    "            algo_2.fit(cold_start_trainset)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            hybrid_predictions = []\n",
    "            true_ratings = []\n",
    "            ndcg_scores = []\n",
    "\n",
    "            for (user, item, true_r) in final_testset:\n",
    "                pred = hybrid_func(user, item, algo, algo_2)\n",
    "                if not np.isnan(pred) and not np.isnan(true_r):\n",
    "                    hybrid_predictions.append(pred)\n",
    "                    true_ratings.append(true_r)\n",
    "                    \n",
    "                    # Calculate NDCG@K for each user\n",
    "                    user_test_ratings = test_df[test_df['user'] == user]\n",
    "                    true_liked_movies = user_test_ratings[user_test_ratings['rating'] >= 4]['item'].tolist()\n",
    "                    \n",
    "                    if true_liked_movies:\n",
    "                        predictions = [(movie_id, hybrid_func(user, movie_id, algo)) for movie_id in unseen_movies_dict[user]]\n",
    "                        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                        top_k_movies = [movie_id for movie_id, _ in predictions[:k]]\n",
    "                        \n",
    "                        ndcg = calculate_ndcg_at_k(top_k_movies, true_liked_movies, k=k)\n",
    "                        ndcg_scores.append(ndcg)\n",
    "\n",
    "            # Evaluate\n",
    "            rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "            mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "            mse = mean_squared_error(true_ratings, hybrid_predictions)\n",
    "            average_ndcg = np.mean(ndcg_scores)\n",
    "            \n",
    "            rmse_results.append((known_ratings, rmse))\n",
    "            mae_results.append((known_ratings, mae))\n",
    "            mse_results.append((known_ratings, mse))\n",
    "            ndcg_results.append((known_ratings, average_ndcg))\n",
    "            \n",
    "            print(f\"RMSE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {rmse}\")\n",
    "            print(f\"MAE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {mae}\")\n",
    "            print(f\"MSE on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {mse}\")\n",
    "            print(f\"NDCG@{k} on filtered cold-start test users (with {known_ratings} training ratings each) for {hybrid_name}: {average_ndcg}\")\n",
    "\n",
    "        # Create a DataFrame to store the results for the current model\n",
    "        results_df = pd.DataFrame({\n",
    "            'Model': hybrid_name,\n",
    "            'Known Ratings': [r[0] for r in rmse_results],\n",
    "            'RMSE': [r[1] for r in rmse_results],\n",
    "            'MAE': [r[1] for r in mae_results],\n",
    "            'MSE': [r[1] for r in mse_results],\n",
    "            'NDCG@K': [r[1] for r in ndcg_results]\n",
    "        })\n",
    "\n",
    "        # Append the results to the all_results list\n",
    "        all_results.append(results_df)\n",
    "\n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    return final_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd532a2",
   "metadata": {},
   "source": [
    "<h4>Run hybrid models with cold start data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ee00305",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_functions = [\n",
    "    basic_weighted_hybrid_predict,\n",
    "    # switiching_weighted_hybrid_predict,\n",
    "    # ensemble_weighted_hybrid_predict,\n",
    "]\n",
    "\n",
    "hybrid_names = [\n",
    "    'Basic Weighted Hybrid',\n",
    "    # 'Switching Weighted Hybrid',\n",
    "    # 'Ensemble Weighted Hybrid',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4f0f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "svd = SVD()\n",
    "knn = KNNBasic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6498e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for 5 known ratings per user with Basic Weighted Hybrid...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "109651",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_hybrid_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhybrid_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meligible_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_ratings_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_results_df)\n",
      "Cell \u001b[0;32mIn[58], line 64\u001b[0m, in \u001b[0;36mrun_hybrid_models\u001b[0;34m(hybrid_functions, hybrid_names, algo, train_df, test_df, eligible_users, known_ratings_list, k)\u001b[0m\n\u001b[1;32m     61\u001b[0m true_liked_movies \u001b[38;5;241m=\u001b[39m user_test_ratings[user_test_ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m true_liked_movies:\n\u001b[0;32m---> 64\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [(movie_id, hybrid_func(user, movie_id, algo)) \u001b[38;5;28;01mfor\u001b[39;00m movie_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43munseen_movies_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     65\u001b[0m     predictions\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m     top_k_movies \u001b[38;5;241m=\u001b[39m [movie_id \u001b[38;5;28;01mfor\u001b[39;00m movie_id, _ \u001b[38;5;129;01min\u001b[39;00m predictions[:k]]\n",
      "\u001b[0;31mKeyError\u001b[0m: 109651"
     ]
    }
   ],
   "source": [
    "final_results_df = run_hybrid_models(hybrid_functions, hybrid_names, svd,  train_df, test_df, eligible_users, known_ratings_list)\n",
    "print(final_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_hybrid_functions = [\n",
    "    # basic_weighted_hybrid_predict,\n",
    "    # switiching_weighted_hybrid_predict,\n",
    "    ensemble_weighted_hybrid_predict,\n",
    "]\n",
    "\n",
    "ensemble_hybrid_names = [\n",
    "    # 'Basic Weighted Hybrid',\n",
    "    # 'Switching Weighted Hybrid',\n",
    "    'Ensemble Weighted Hybrid',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for 5 known ratings per user with Basic Weighted Hybrid...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/1314150144.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hybrid_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meligible_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_ratings_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_results_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2202415762.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(hybrid_functions, hybrid_names, algo, train_df, test_df, eligible_users, known_ratings_list, k)\u001b[0m\n",
      "\u001b[1;32m     56\u001b[0m                         \u001b[0mall_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     57\u001b[0m                         \u001b[0mseen_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m                         \u001b[0munseen_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_movies\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mseen_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 60\u001b[0;31m                         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munseen_movies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     61\u001b[0m                         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     62\u001b[0m                         \u001b[0mtop_k_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmovie_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2202415762.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrun_hybrid_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meligible_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_ratings_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhybrid_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/3299621061.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(user_id, item_id, algo)\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     10\u001b[0m         \u001b[0mcolab_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Content-based prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcontent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_content_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Weighted combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m     \u001b[0mhybrid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolab_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcolab_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontent_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcontent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/3822803765.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(user_id, item_id)\u001b[0m\n",
      "\u001b[1;32m     20\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Item {item_id} not found in item_profiles.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# If user or item not found (cold start for genre), return global mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   1187\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n",
      "\u001b[1;32m   1427\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1429\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, label, axis)\u001b[0m\n",
      "\u001b[1;32m   1379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# GH#5567 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n",
      "\u001b[1;32m   4332\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4334\u001b[0m         \u001b[0;31m# this could be a view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4335\u001b[0m         \u001b[0;31m# but only in a single-dtyped view sliceable case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 4336\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   4337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, ref, copy)\u001b[0m\n",
      "\u001b[1;32m   4381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4382\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4383\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   4384\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 4385\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_results_df_2 = run_ensemble_hybrid_models(ensemble_hybrid_functions, ensemble_hybrid_names, svd, knn, train_df, test_df, eligible_users, known_ratings_list)\n",
    "print(final_results_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df3822",
   "metadata": {},
   "source": [
    "<h4>Prediction</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1129406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the testset\n",
    "# basic_weighted_hybrid_predictions = []\n",
    "# basic_weighted_true_ratings = []\n",
    "\n",
    "# for (user, item, true_r) in testset:\n",
    "#     pred = basic_weighted_hybrid_predict(user, item, svd, colab_weight=0.7, content_weight=0.3)\n",
    "#     # Ensure predictions and true ratings are not NaN\n",
    "#     if not np.isnan(pred) and not np.isnan(true_r):\n",
    "#         basic_weighted_hybrid_predictions.append(pred)\n",
    "#         basic_weighted_true_ratings.append(true_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Evaluate Hybrid Model\n",
    "# # Calculate RMSE\n",
    "# rmse = np.sqrt(mean_squared_error(basic_weighted_true_ratings, basic_weighted_hybrid_predictions))\n",
    "# mae = mean_absolute_error(basic_weighted_true_ratings, basic_weighted_hybrid_predictions)\n",
    "\n",
    "# print(f\"Hybrid Model RMSE: {rmse:.4f}\")\n",
    "# print(f\"Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe651b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the testset\n",
    "# switiching_weighted_hybrid_predictions = []\n",
    "# switiching_weighted_true_ratings = []\n",
    "\n",
    "# for (user, item, true_r) in testset:\n",
    "#     pred = switiching_weighted_hybrid_predict(user, item)\n",
    "#     # Ensure predictions and true ratings are not NaN\n",
    "#     if not np.isnan(pred) and not np.isnan(true_r):\n",
    "#         switiching_weighted_hybrid_predictions.append(pred)\n",
    "#         switiching_weighted_true_ratings.append(true_r)\n",
    "\n",
    "# # Step 5: Evaluate Hybrid Model\n",
    "# # Calculate RMSE\n",
    "# rmse = np.sqrt(mean_squared_error(switiching_weighted_true_ratings, switiching_weighted_hybrid_predictions))\n",
    "# mae = mean_absolute_error(switiching_weighted_true_ratings, switiching_weighted_hybrid_predictions)\n",
    "\n",
    "# print(f\"Weighted Hybrid Model RMSE: {rmse:.4f}\")\n",
    "# print(f\"Weighted Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1691627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 4. Train the KNN Model\n",
    "# knn = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "# knn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ede2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the testset\n",
    "# ensemble_weighted_hybrid_predictions = []\n",
    "# ensemble_weighted_true_ratings = []\n",
    "\n",
    "# for (user, item, true_r) in testset:\n",
    "#     pred = ensemble_weighted_hybrid_predict(user, item)\n",
    "#     # Ensure predictions and true ratings are not NaN\n",
    "#     if not np.isnan(pred) and not np.isnan(true_r):\n",
    "#         ensemble_weighted_hybrid_predictions.append(pred)\n",
    "#         ensemble_weighted_true_ratings.append(true_r)\n",
    "\n",
    "# # Step 6: Evaluate Hybrid Model\n",
    "# # Calculate RMSE\n",
    "# rmse = np.sqrt(mean_squared_error(ensemble_weighted_true_ratings, ensemble_weighted_hybrid_predictions))\n",
    "# mae = mean_absolute_error(ensemble_weighted_true_ratings, ensemble_weighted_hybrid_predictions)\n",
    "# print(f\"Knn Hybrid Model RMSE: {rmse:.4f}\")\n",
    "# print(f\"Knn Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the SVD model\n",
    "# svdpp = SVDpp()\n",
    "# svdpp.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ca95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the testset\n",
    "# hybrid_predictions = []\n",
    "# true_ratings = []\n",
    "\n",
    "# for (user, item, true_r) in testset:\n",
    "#     pred = svdpp_weighted_hybrid_predict(user, item)\n",
    "#     # Ensure predictions and true ratings are not NaN\n",
    "#     if not np.isnan(pred) and not np.isnan(true_r):\n",
    "#         hybrid_predictions.append(pred)\n",
    "#         true_ratings.append(true_r)\n",
    "\n",
    "# # Step 6: Evaluate Hybrid Model\n",
    "# # Calculate RMSE\n",
    "# rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "# mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "# print(f\"SVDpp Hybrid Model RMSE: {rmse:.4f}\")\n",
    "# print(f\"SVDpp Hybrid Model MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
