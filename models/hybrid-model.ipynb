{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb64454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "from surprise import BaselineOnly, Dataset, Reader, SVD, NMF, SVDpp, accuracy, PredictionImpossible, KNNWithMeans, KNNBasic\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV, PredefinedKFold\n",
    "from surprise.model_selection.split import LeaveOneOut\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52e7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/1792210709.py:9: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/1792210709.py:9: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x31d63f310>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', \n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "column_names = [\"item\",\"title\",\"genres\",\"movie_name\",\"movie_year\",\"(no genres listed)\",\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"IMAX\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\",\"user\",\"rating\",\"rating_timestamp\",\"rating_year\",\"rating_month\",\"rating_season,tag\",\"tag_timestamp\",\"cleaned_tag\",\"tag_length\",\"tag_year\"]\n",
    "\n",
    "data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "ratings = data[['user', 'item', 'rating']]\n",
    "ratings = ratings.iloc[1:]\n",
    "ratings[\"rating\"] = ratings[\"rating\"].astype(float)\n",
    "\n",
    "custom_data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "print(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "165926d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "trainset, testset = train_test_split(custom_data, test_size=0.2)\n",
    "\n",
    "# Convert trainset to dataframe (for content-based model)\n",
    "train_df = pd.DataFrame(trainset.build_testset(), columns=['user', 'item', 'rating'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918e97d",
   "metadata": {},
   "source": [
    "Grid Search CV with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb2746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_param_grid = {\n",
    "    \"n_factors\":[50, 100],\n",
    "    \"lr_all\":[0.002, 0.005],\n",
    "    \"reg_all\": [0.02, 0.1]\n",
    "}\n",
    "\n",
    "svd_grid = GridSearchCV(SVD, svd_param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "svd_grid.fit(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae850a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x14a537d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVD model\n",
    "# svd = SVD()\n",
    "# svd.fit(trainset)\n",
    "svd = svd_grid.best_estimator[\"rmse\"]\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e7644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2531497710.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies[genre_cols] = movies[genre_cols].astype(bool)\n",
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_18572/2531497710.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies[genre_cols] = movies[genre_cols].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [item, title, Action, Adventure, Animation, Children, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movies = data[['item', 'title'] + genre_cols]\n",
    "movies[genre_cols] = movies[genre_cols].astype(bool)\n",
    "movies[genre_cols] = movies[genre_cols].astype(int)\n",
    "# movies = movies.rename(columns={'movieId': 'item'})\n",
    "movies = movies.drop_duplicates(subset='item', keep='first')\n",
    "\n",
    "# Check for duplicate 'item' IDs\n",
    "duplicate_items = movies[movies.duplicated(subset='item', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(duplicate_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f42c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of item_profiles: (15318, 18)\n",
      "No duplicate item_ids found in item_profiles.\n"
     ]
    }
   ],
   "source": [
    "# 4. Build User Profiles for Content-Based Recommender\n",
    "# Step 4.1: Merge ratings and movie genres\n",
    "train_merged = pd.merge(train_df[['user', 'item']], data, on=['user', 'item'], how='inner')\n",
    "train_merged = train_merged[['user', 'item', 'rating', \"title\"]+genre_cols]\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(bool)\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(int)\n",
    "\n",
    "# Step 4.2: Create user profiles based on genres\n",
    "user_profiles = train_merged.groupby('user')[genre_cols].mean()\n",
    "\n",
    "# Normalize user profiles (optional, helps with cosine similarity)\n",
    "user_profiles = user_profiles.div(user_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# 5. Build Item Profile Matrix\n",
    "item_profiles = movies.set_index('item')[genre_cols]\n",
    "item_profiles = item_profiles.div(item_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "# Count the number of ratings per user\n",
    "user_rating_counts = train_df['user'].value_counts()\n",
    "\n",
    "# Debugging: Check the shape of item_profiles\n",
    "print(f\"Shape of item_profiles: {item_profiles.shape}\")\n",
    "\n",
    "# Check for duplicate item_ids in item_profiles\n",
    "if item_profiles.index.duplicated().any():\n",
    "    print(\"Duplicate item_ids found in item_profiles.\")\n",
    "else:\n",
    "    print(\"No duplicate item_ids found in item_profiles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee643c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make Predictions\n",
    "# Helper function: Content-based rating prediction\n",
    "def predict_content_based(user_id, item_id):\n",
    "    try:\n",
    "        # Get the user profile and item profile\n",
    "        user_vector = user_profiles.loc[user_id]\n",
    "        \n",
    "        # Ensure item_id is a valid index in item_profiles\n",
    "        if item_id in item_profiles.index:\n",
    "            item_vector = item_profiles.loc[item_id]\n",
    "            if item_vector.ndim == 1:\n",
    "                # Cosine similarity between user and item vectors\n",
    "                similarity = np.dot(user_vector, item_vector) / (np.linalg.norm(user_vector) * np.linalg.norm(item_vector))\n",
    "                # Scale similarity to rating scale (1-5)\n",
    "                # Since similarity can be from -1 to 1, we adjust it:\n",
    "                predicted_rating = 2.5 + 2.5 * similarity  # Center at 2.5, range approx 1-5\n",
    "                return np.clip(predicted_rating, 1.0, 5.0)\n",
    "            else:\n",
    "                print(f\"item_vector for item {item_id} is not 1-dimensional.\")\n",
    "                return train_df['rating'].mean()\n",
    "        else:\n",
    "            print(f\"Item {item_id} not found in item_profiles.\")\n",
    "            return train_df['rating'].mean()\n",
    "    except KeyError:\n",
    "        # If user or item not found (cold start for genre), return global mean\n",
    "        return train_df['rating'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f27053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def hybrid_predict(user_id, item_id, svd_weight=0.5, content_weight=0.5):\n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1129406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testset\n",
    "hybrid_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = hybrid_predict(user, item, svd_weight=0.7, content_weight=0.3)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        hybrid_predictions.append(pred)\n",
    "        true_ratings.append(true_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f7b6806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model RMSE: 0.8569\n",
      "Hybrid Model MAE: 0.6666\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "\n",
    "print(f\"Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f0c0e",
   "metadata": {},
   "source": [
    "<h1>Same model with weighted average for cold start problem</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b0b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def weighted_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        content_weight = 1.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        content_weight = 0.8\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        content_weight = 0.2\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe651b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Hybrid Model RMSE: 0.8472\n",
      "Weighted Hybrid Model MAE: 0.6561\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testset\n",
    "hybrid_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = weighted_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        hybrid_predictions.append(pred)\n",
    "        true_ratings.append(true_r)\n",
    "\n",
    "# Step 5: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "\n",
    "print(f\"Weighted Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Weighted Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dd97d",
   "metadata": {},
   "source": [
    "<h1>Hybrid using KNN modal over cosine</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1691627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Train the KNN Model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNNBasic(sim_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_based\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m----> 3\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/surprise/prediction_algorithms/knns.py:98\u001b[0m, in \u001b[0;36mKNNBasic.fit\u001b[0;34m(self, trainset)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainset):\n\u001b[1;32m     97\u001b[0m     SymmetricAlgo\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m, trainset)\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/movie_recommender_3/lib/python3.10/site-packages/surprise/prediction_algorithms/algo_base.py:248\u001b[0m, in \u001b[0;36mAlgoBase.compute_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m similarity matrix...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m sim \u001b[38;5;241m=\u001b[39m \u001b[43mconstruction_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone computing similarity matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Train the KNN Model\n",
    "knn = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "knn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def knn_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        knn_weight = 1.0\n",
    "        # knn_weight = 0.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        knn_weight = 0.8\n",
    "        # knn_weight = 0.0\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        knn_weight = 0.5\n",
    "        # knn_weight = 0.0\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        knn_weight = 0.2\n",
    "        # knn_weight = 0.0\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # KNN prediction\n",
    "    try:\n",
    "        knn_pred = knn.predict(user_id, item_id).est\n",
    "    except:\n",
    "        knn_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (knn_weight * knn_pred) \n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ede2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn Hybrid Model RMSE: 0.8313\n",
      "Knn Hybrid Model MAE: 0.6430\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testset\n",
    "hybrid_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = knn_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        hybrid_predictions.append(pred)\n",
    "        true_ratings.append(true_r)\n",
    "\n",
    "# Step 6: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "print(f\"Knn Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Knn Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eef6e0",
   "metadata": {},
   "source": [
    "<h1>Hybrid using cosine and SVD++</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b10ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x33b8b4af0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVD model\n",
    "svdpp = SVDpp()\n",
    "svdpp.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hybrid prediction function\n",
    "def svdpp_weighted_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        content_weight = 1.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        content_weight = 0.8\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        content_weight = 0.2\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svdpp_pred = svdpp.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svdpp_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svdpp_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ca95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDpp Hybrid Model RMSE: 0.8328\n",
      "SVDpp Hybrid Model MAE: 0.6432\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testset\n",
    "hybrid_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = svdpp_weighted_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        hybrid_predictions.append(pred)\n",
    "        true_ratings.append(true_r)\n",
    "\n",
    "# Step 6: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "print(f\"SVDpp Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"SVDpp Hybrid Model MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
