{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c7833d",
   "metadata": {},
   "source": [
    "<h4>Import and setup</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb64454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "from surprise import BaselineOnly, Dataset, Reader, SVD, NMF, SVDpp, accuracy, PredictionImpossible, KNNWithMeans, KNNBasic\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV, PredefinedKFold\n",
    "from surprise.model_selection.split import LeaveOneOut\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', \n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "column_names = [\"item\",\"title\",\"genres\",\"movie_name\",\"movie_year\",\"(no genres listed)\",\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"IMAX\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\",\"user\",\"rating\",\"rating_timestamp\",\"rating_year\",\"rating_month\",\"rating_season,tag\",\"tag_timestamp\",\"cleaned_tag\",\"tag_length\",\"tag_year\"]\n",
    "\n",
    "data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "ratings = data[['user', 'item', 'rating']]\n",
    "ratings = ratings.iloc[1:]\n",
    "ratings[\"rating\"] = ratings[\"rating\"].astype(float)\n",
    "\n",
    "custom_data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "print(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165926d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "trainset, testset = train_test_split(custom_data, test_size=0.2)\n",
    "\n",
    "# Convert trainset to dataframe (for content-based model)\n",
    "train_df = pd.DataFrame(trainset.build_testset(), columns=['user', 'item', 'rating'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918e97d",
   "metadata": {},
   "source": [
    "<h4>Grid Search CV with SVD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_param_grid = {\n",
    "    \"n_factors\":[50, 100],\n",
    "    \"lr_all\":[0.002, 0.005],\n",
    "    \"reg_all\": [0.02, 0.1]\n",
    "}\n",
    "\n",
    "svd_grid = GridSearchCV(SVD, svd_param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "svd_grid.fit(custom_data)\n",
    "\n",
    "# Train the SVD model\n",
    "svd = svd_grid.best_estimator[\"rmse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b63f6",
   "metadata": {},
   "source": [
    "<h4>Movie data setup</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies = data[['item', 'title'] + genre_cols]\n",
    "movies[genre_cols] = movies[genre_cols].astype(bool)\n",
    "movies[genre_cols] = movies[genre_cols].astype(int)\n",
    "# movies = movies.rename(columns={'movieId': 'item'})\n",
    "movies = movies.drop_duplicates(subset='item', keep='first')\n",
    "\n",
    "# Check for duplicate 'item' IDs\n",
    "duplicate_items = movies[movies.duplicated(subset='item', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(duplicate_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66355a72",
   "metadata": {},
   "source": [
    "<h4>Building user profiles for content-based recommender</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f42c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build User Profiles for Content-Based Recommender\n",
    "# Step 4.1: Merge ratings and movie genres\n",
    "train_merged = pd.merge(train_df[['user', 'item']], data, on=['user', 'item'], how='inner')\n",
    "train_merged = train_merged[['user', 'item', 'rating', \"title\"]+genre_cols]\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(bool)\n",
    "train_merged[genre_cols] = train_merged[genre_cols].astype(int)\n",
    "\n",
    "# Step 4.2: Create user profiles based on genres\n",
    "user_profiles = train_merged.groupby('user')[genre_cols].mean()\n",
    "\n",
    "# Normalize user profiles (optional, helps with cosine similarity)\n",
    "user_profiles = user_profiles.div(user_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# 5. Build Item Profile Matrix\n",
    "item_profiles = movies.set_index('item')[genre_cols]\n",
    "item_profiles = item_profiles.div(item_profiles.sum(axis=1), axis=0)\n",
    "\n",
    "# Count the number of ratings per user\n",
    "user_rating_counts = train_df['user'].value_counts()\n",
    "\n",
    "# Debugging: Check the shape of item_profiles\n",
    "print(f\"Shape of item_profiles: {item_profiles.shape}\")\n",
    "\n",
    "# Check for duplicate item_ids in item_profiles\n",
    "if item_profiles.index.duplicated().any():\n",
    "    print(\"Duplicate item_ids found in item_profiles.\")\n",
    "else:\n",
    "    print(\"No duplicate item_ids found in item_profiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80409e",
   "metadata": {},
   "source": [
    "<h4>Content based prediction function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee643c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make Predictions\n",
    "# Helper function: Content-based rating prediction\n",
    "def predict_content_based(user_id, item_id):\n",
    "    try:\n",
    "        # Get the user profile and item profile\n",
    "        user_vector = user_profiles.loc[user_id]\n",
    "        \n",
    "        # Ensure item_id is a valid index in item_profiles\n",
    "        if item_id in item_profiles.index:\n",
    "            item_vector = item_profiles.loc[item_id]\n",
    "            if item_vector.ndim == 1:\n",
    "                # Cosine similarity between user and item vectors\n",
    "                similarity = np.dot(user_vector, item_vector) / (np.linalg.norm(user_vector) * np.linalg.norm(item_vector))\n",
    "                # Scale similarity to rating scale (1-5)\n",
    "                # Since similarity can be from -1 to 1, we adjust it:\n",
    "                predicted_rating = 2.5 + 2.5 * similarity  # Center at 2.5, range approx 1-5\n",
    "                return np.clip(predicted_rating, 1.0, 5.0)\n",
    "            else:\n",
    "                print(f\"item_vector for item {item_id} is not 1-dimensional.\")\n",
    "                return train_df['rating'].mean()\n",
    "        else:\n",
    "            print(f\"Item {item_id} not found in item_profiles.\")\n",
    "            return train_df['rating'].mean()\n",
    "    except KeyError:\n",
    "        # If user or item not found (cold start for genre), return global mean\n",
    "        return train_df['rating'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111f384",
   "metadata": {},
   "source": [
    "<h4>Basic Weighted Hybrid Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def basic_weighted_hybrid_predict(user_id, item_id, svd_weight=0.5, content_weight=0.5):\n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df3822",
   "metadata": {},
   "source": [
    "<h4>Prediction</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1129406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testset\n",
    "basic_weighted_hybrid_predictions = []\n",
    "basic_weighted_true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = basic_weighted_hybrid_predict(user, item, svd_weight=0.7, content_weight=0.3)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        basic_weighted_hybrid_predictions.append(pred)\n",
    "        basic_weighted_true_ratings.append(true_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(basic_weighted_true_ratings, basic_weighted_hybrid_predictions))\n",
    "mae = mean_absolute_error(basic_weighted_true_ratings, basic_weighted_hybrid_predictions)\n",
    "\n",
    "print(f\"Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f0c0e",
   "metadata": {},
   "source": [
    "<h1>Same model with switching for cold start problem</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def switiching_weighted_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        content_weight = 1.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        content_weight = 0.8\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        content_weight = 0.2\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe651b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testset\n",
    "switiching_weighted_hybrid_predictions = []\n",
    "switiching_weighted_true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = switiching_weighted_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        switiching_weighted_hybrid_predictions.append(pred)\n",
    "        switiching_weighted_true_ratings.append(true_r)\n",
    "\n",
    "# Step 5: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(switiching_weighted_true_ratings, switiching_weighted_hybrid_predictions))\n",
    "mae = mean_absolute_error(switiching_weighted_true_ratings, switiching_weighted_hybrid_predictions)\n",
    "\n",
    "print(f\"Weighted Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Weighted Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dd97d",
   "metadata": {},
   "source": [
    "<h1>Ensemble switching hybrid (KNN and SVD)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1691627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Train the KNN Model\n",
    "knn = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "knn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid prediction function\n",
    "def ensemble_weighted_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        knn_weight = 1.0\n",
    "        # knn_weight = 0.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        knn_weight = 0.8\n",
    "        # knn_weight = 0.0\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        knn_weight = 0.5\n",
    "        # knn_weight = 0.0\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        knn_weight = 0.2\n",
    "        # knn_weight = 0.0\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svd_pred = svd.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svd_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # KNN prediction\n",
    "    try:\n",
    "        knn_pred = knn.predict(user_id, item_id).est\n",
    "    except:\n",
    "        knn_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svd_pred) + (knn_weight * knn_pred) \n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ede2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testset\n",
    "ensemble_weighted_hybrid_predictions = []\n",
    "ensemble_weighted_true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = ensemble_weighted_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        ensemble_weighted_hybrid_predictions.append(pred)\n",
    "        ensemble_weighted_true_ratings.append(true_r)\n",
    "\n",
    "# Step 6: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(ensemble_weighted_true_ratings, ensemble_weighted_hybrid_predictions))\n",
    "mae = mean_absolute_error(ensemble_weighted_true_ratings, ensemble_weighted_hybrid_predictions)\n",
    "print(f\"Knn Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Knn Hybrid Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eef6e0",
   "metadata": {},
   "source": [
    "<h1>Switching Hybrid using SVD++</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVD model\n",
    "svdpp = SVDpp()\n",
    "svdpp.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hybrid prediction function\n",
    "def svdpp_weighted_hybrid_predict(user_id, item_id):\n",
    "    # Determine the number of ratings for the user\n",
    "    num_ratings = user_rating_counts.get(user_id, 0)\n",
    "    \n",
    "    # Set weights based on the number of ratings\n",
    "    if num_ratings == 0:\n",
    "        svd_weight = 0.0\n",
    "        content_weight = 1.0\n",
    "    elif 1 <= num_ratings <= 5:\n",
    "        svd_weight = 0.2\n",
    "        content_weight = 0.8\n",
    "    elif 6 <= num_ratings <= 10:\n",
    "        svd_weight = 0.5\n",
    "        content_weight = 0.5\n",
    "    else:\n",
    "        svd_weight = 0.8\n",
    "        content_weight = 0.2\n",
    "    \n",
    "    # SVD prediction\n",
    "    try:\n",
    "        svdpp_pred = svdpp.predict(user_id, item_id).est\n",
    "    except:\n",
    "        svdpp_pred = train_df['rating'].mean()\n",
    "    \n",
    "    # Content-based prediction\n",
    "    content_pred = predict_content_based(user_id, item_id)\n",
    "    \n",
    "    # Weighted combination\n",
    "    hybrid_pred = (svd_weight * svdpp_pred) + (content_weight * content_pred)\n",
    "    return np.clip(hybrid_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ca95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testset\n",
    "hybrid_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "for (user, item, true_r) in testset:\n",
    "    pred = svdpp_weighted_hybrid_predict(user, item)\n",
    "    # Ensure predictions and true ratings are not NaN\n",
    "    if not np.isnan(pred) and not np.isnan(true_r):\n",
    "        hybrid_predictions.append(pred)\n",
    "        true_ratings.append(true_r)\n",
    "\n",
    "# Step 6: Evaluate Hybrid Model\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings, hybrid_predictions))\n",
    "mae = mean_absolute_error(true_ratings, hybrid_predictions)\n",
    "print(f\"SVDpp Hybrid Model RMSE: {rmse:.4f}\")\n",
    "print(f\"SVDpp Hybrid Model MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
