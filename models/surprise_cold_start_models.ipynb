{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "from surprise import BaselineOnly, Dataset, Reader, SVD, NMF, SVDpp, accuracy, PredictionImpossible, KNNWithMeans, KNNBasic, NormalPredictor, KNNWithZScore, KNNBaseline, SlopeOne, CoClustering\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV, PredefinedKFold\n",
    "from surprise.model_selection.split import LeaveOneOut\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_30804/2547392058.py:9: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_30804/2547392058.py:9: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', \n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "column_names = [\"item\",\"title\",\"genres\",\"movie_name\",\"movie_year\",\"(no genres listed)\",\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"IMAX\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\",\"user\",\"rating\",\"rating_timestamp\",\"rating_year\",\"rating_month\",\"rating_season,tag\",\"tag_timestamp\",\"cleaned_tag\",\"tag_length\",\"tag_year\"]\n",
    "\n",
    "data = pd.read_csv('../samples/combined_movies_ratings_tags.csv', names=column_names, index_col=False, skiprows=0)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "ratings = data[['user', 'item', 'rating']]\n",
    "ratings = ratings.iloc[1:]\n",
    "ratings[\"rating\"] = ratings[\"rating\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial testing creating a dataset of 10k users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = Dataset.load_from_df(ratings, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train test split</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "trainset, testset = train_test_split(custom_data, test_size=0.2)\n",
    "\n",
    "# Convert trainset to dataframe (for content-based model)\n",
    "train_df = pd.DataFrame(trainset.build_testset(), columns=['user', 'item', 'rating'])\n",
    "test_df = pd.DataFrame(testset, columns=['user', 'item', 'rating'])\n",
    "\n",
    "\n",
    "# Step 1: Filter users with >= 5 test ratings\n",
    "test_user_counts = test_df['user'].value_counts()\n",
    "eligible_users = test_user_counts[test_user_counts >= 5].index.tolist()\n",
    "\n",
    "# Different number of known ratings to test\n",
    "# known_ratings_list = [5]\n",
    "known_ratings_list = [5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the best params for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "measures=[\"rmse\", \"mae\", \"mse\"]\n",
    "\n",
    "def perform_grid_search(algo, params):\n",
    "    \n",
    "    gs = GridSearchCV(algo, params, measures=measures, cv=3,  joblib_verbose=0)\n",
    "\n",
    "    gs.fit(custom_data)\n",
    "\n",
    "    \n",
    "    # best RMSE score\n",
    "    print(gs.best_score)\n",
    "\n",
    "\n",
    "    # combination of parameters that gave the best measure score\n",
    "    print(gs.best_params)\n",
    "    return gs.best_estimator[\"rmse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run the cold start train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cold_start_models(models, model_names, train_df, test_df, eligible_users, known_ratings_list, k=10):\n",
    "    all_results = []\n",
    "\n",
    "    for algo, model_name in zip(models, model_names):\n",
    "        rmse_results = []\n",
    "        mae_results = []\n",
    "        mse_results = []\n",
    "        ndcg_results = []\n",
    "\n",
    "        # Iterate over each number of known ratings\n",
    "        for known_ratings in known_ratings_list:\n",
    "            print(f\"Processing for {known_ratings} known ratings per user with {model_name}...\")\n",
    "            \n",
    "            # Step 3: Reduce training data to 'known_ratings' ratings per user for these test users (simulate cold start)\n",
    "            limited_train_rows = []\n",
    "            for user in eligible_users:\n",
    "                user_ratings = train_df[train_df['user'] == user]\n",
    "                if len(user_ratings) > known_ratings:\n",
    "                    sampled = user_ratings.sample(known_ratings, random_state=42)\n",
    "                else:\n",
    "                    sampled = user_ratings\n",
    "                limited_train_rows.append(sampled)\n",
    "\n",
    "            # Step 4: Add all training data from non-eligible users (normal users)\n",
    "            non_eligible_users_df = train_df[~train_df['user'].isin(eligible_users)]\n",
    "            cold_start_train_df = pd.concat(limited_train_rows + [non_eligible_users_df], ignore_index=True)\n",
    "\n",
    "            # Build training set for Surprise\n",
    "            reader = Reader(rating_scale=(train_df['rating'].min(), train_df['rating'].max()))\n",
    "            cold_start_data = Dataset.load_from_df(cold_start_train_df[['user', 'item', 'rating']], reader)\n",
    "            cold_start_trainset = cold_start_data.build_full_trainset()\n",
    "\n",
    "            # Train the model\n",
    "            algo.fit(cold_start_trainset)\n",
    "\n",
    "            # Build the final test set for Surprise\n",
    "            final_testset = [tuple(x) for x in test_df.to_numpy()]\n",
    "            predictions = algo.test(final_testset)\n",
    "\n",
    "            # Evaluate\n",
    "            rmse = accuracy.rmse(predictions, verbose=False)\n",
    "            mae = accuracy.mae(predictions, verbose=False)\n",
    "            mse = accuracy.mse(predictions, verbose=False)\n",
    "            \n",
    "            rmse_results.append((known_ratings, rmse))\n",
    "            mae_results.append((known_ratings, mae))\n",
    "            mse_results.append((known_ratings, mse))\n",
    "            \n",
    "            print(f\"RMSE on filtered cold-start test users (with {known_ratings} training ratings each) for {model_name}: {rmse}\")\n",
    "            print(f\"MAE on filtered cold-start test users (with {known_ratings} training ratings each) for {model_name}: {mae}\")\n",
    "            print(f\"MSE on filtered cold-start test users (with {known_ratings} training ratings each) for {model_name}: {mse}\")\n",
    "\n",
    "            # Calculate NDCG@K\n",
    "            # Calculate NDCG@K\n",
    "            ndcg_scores = []\n",
    "            for user_id in eligible_users:\n",
    "                user_ratings = train_df[train_df['user'] == user_id]\n",
    "                \n",
    "                # Predict ratings for unseen movies\n",
    "                all_movies = set(train_df['item'].unique())\n",
    "                seen_movies = set(user_ratings['item'])\n",
    "                unseen_movies = list(all_movies - seen_movies)\n",
    "                \n",
    "                # Filter test data for the current user\n",
    "                user_test_ratings = test_df[test_df['user'] == user_id]\n",
    "                if user_test_ratings.empty:\n",
    "                    continue  # Skip user if no test data\n",
    "                \n",
    "                predictions = [ (movie_id, algo.predict(user_id, movie_id).est) for movie_id in unseen_movies ]\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                # Top-K recommended movies\n",
    "                top_k_movies = [movie_id for movie_id, _ in predictions[:k]]\n",
    "                \n",
    "                # Movies the user actually liked (rating >= 4) in the test set\n",
    "                true_liked_movies = user_test_ratings[user_test_ratings['rating'] >= 4]['item'].tolist()\n",
    "                \n",
    "                if not true_liked_movies:\n",
    "                    continue  # Skip user if no strong likes in the test set\n",
    "                \n",
    "                # --- Calculate NDCG@K ---\n",
    "                dcg = 0.0\n",
    "                for idx, movie_id in enumerate(top_k_movies):\n",
    "                    if movie_id in true_liked_movies:\n",
    "                        dcg += 1.0 / np.log2(idx + 2)  # +2 because index starts from 0\n",
    "                \n",
    "                # Ideal DCG (IDCG)\n",
    "                ideal_relevant = min(len(true_liked_movies), k)\n",
    "                idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_relevant))\n",
    "                \n",
    "                ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "                ndcg_scores.append(ndcg)\n",
    "\n",
    "            average_ndcg = np.mean(ndcg_scores)\n",
    "            ndcg_results.append((known_ratings, average_ndcg))\n",
    "            print(f\"NDCG@{k} on filtered cold-start test users (with {known_ratings} training ratings each) for {model_name}: {average_ndcg}\")\n",
    "\n",
    "        # Create a DataFrame to store the results for the current model\n",
    "        results_df = pd.DataFrame({\n",
    "            'Model': model_name,\n",
    "            'Known Ratings': [r[0] for r in rmse_results],\n",
    "            'RMSE': [r[1] for r in rmse_results],\n",
    "            'MAE': [r[1] for r in mae_results],\n",
    "            'MSE': [r[1] for r in mse_results],\n",
    "            'NDCG@K': [r[1] for r in ndcg_results]\n",
    "        })\n",
    "\n",
    "        # Append the results to the all_results list\n",
    "        all_results.append(results_df)\n",
    "\n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    return final_results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grid search for best params<h3>\n",
    "\n",
    "First create a reusable function to run grid search for any model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SVD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svd = {\n",
    "    'n_factors': [20, 50, 100, 150, 200],\n",
    "    'n_epochs': [20, 30, 40, 50, 60],\n",
    "    'lr_all': [0.002, 0.005, 0.007, 0.01, 0.02],\n",
    "    'reg_all': [0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "# best_svd = perform_grid_search(SVD, param_grid_svd)\n",
    "\n",
    "# models += [best_svd]\n",
    "models += [SVD()]\n",
    "model_names += ['SVD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SVD++</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svdpp = {\n",
    "    'n_factors': [20, 50, 100, 150, 200],\n",
    "    'n_epochs': [10, 20, 30, 40, 50],\n",
    "    'lr_all': [0.002, 0.005, 0.007, 0.01, 0.02],\n",
    "    'reg_all': [0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "# best_svdpp = perform_grid_search(SVDpp, param_grid_svdpp)\n",
    "\n",
    "# models += [best_svdpp]\n",
    "models += [SVDpp()]\n",
    "model_names += ['SVD++']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>NMF</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nmf = {\n",
    "    'n_factors': [15, 30, 50, 100, 150],\n",
    "    'n_epochs': [50, 100, 150, 200, 300],\n",
    "    'reg_pu': [0.06, 0.08, 0.1, 0.2, 0.3],\n",
    "    'reg_qi': [0.06, 0.08, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# best_nmf = perform_grid_search(NMF, param_grid_nmf)\n",
    "\n",
    "# models += [best_nmf]\n",
    "models += [NMF()]\n",
    "model_names += ['NMF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNN basic</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn_basic = {\n",
    "    'k': [10, 20, 30, 40, 50],\n",
    "    'min_k': [1, 3, 5, 7, 10],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson', 'pearson_baseline'],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# best_knn_basic = perform_grid_search(KNNBasic, param_grid_knn_basic)\n",
    "\n",
    "# models += [best_knn_basic]\n",
    "models += [KNNBasic()]\n",
    "\n",
    "model_names += ['KNNBasic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNN with means</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn_means = {\n",
    "    'k': [10, 20, 30, 40, 50],\n",
    "    'min_k': [1, 3, 5, 7, 10],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson_baseline'],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# best_knn_with_means = perform_grid_search(KNNWithMeans, param_grid_knn_means)\n",
    "\n",
    "# models += [best_knn_with_means]\n",
    "models += [KNNWithMeans()]\n",
    "model_names += ['KNNWithMeans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNN with Z Score</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn_zscore = {\n",
    "    'k': [10, 20, 30, 40, 50],\n",
    "    'min_k': [1, 3, 5, 7, 10],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson'],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# best_knn_z_score = perform_grid_search(KNNWithZScore, param_grid_knn_zscore)\n",
    "\n",
    "# models += [best_knn_z_score]\n",
    "models += [KNNWithZScore()]\n",
    "model_names += ['KNNWithZScore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNN with Baseline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn_baseline = {\n",
    "    'k': [10, 20, 30, 40, 50],\n",
    "    'min_k': [1, 3, 5, 7, 10],\n",
    "    'sim_options': {\n",
    "        'name': ['pearson_baseline', 'cosine'],\n",
    "        'user_based': [True, False]\n",
    "    },\n",
    "    'bsl_options': {\n",
    "        'method': ['sgd', 'als'],\n",
    "        'reg': [0.01, 0.02, 0.05, 0.1],\n",
    "        'learning_rate': [0.002, 0.005, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "# best_knn_baseline = perform_grid_search(KNNBaseline, param_grid_knn_baseline)\n",
    "\n",
    "# models += [best_knn_baseline]\n",
    "models += [KNNBaseline()]\n",
    "model_names += ['KNNBaseline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CoClustering</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_coclustering = {\n",
    "    'n_cltr_u': [3, 5, 10, 15, 20],\n",
    "    'n_cltr_i': [3, 5, 10, 15, 20],\n",
    "    'n_epochs': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# best_coclustering = perform_grid_search(CoClustering, param_grid_coclustering)\n",
    "\n",
    "# models += [best_coclustering]\n",
    "models += [CoClustering()]\n",
    "model_names += ['CoClustering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Baseline Only</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_baseline_only = {\n",
    "    'bsl_options': {\n",
    "        'method': ['sgd', 'als'],\n",
    "        'reg': [0.01, 0.02, 0.05, 0.1],\n",
    "        'learning_rate': [0.002, 0.005, 0.01],\n",
    "        'n_epochs': [5, 10, 20, 30, 40]\n",
    "    }\n",
    "}\n",
    "\n",
    "# best_baseline_only = perform_grid_search(BaselineOnly, param_grid_baseline_only)\n",
    "\n",
    "# models += [best_baseline_only]\n",
    "models += [BaselineOnly()]\n",
    "model_names += ['BaselineOnly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Models with no parameters</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeone_algo = SlopeOne()\n",
    "normalPredictor_algo = NormalPredictor()\n",
    "\n",
    "\n",
    "models += [slopeone_algo, normalPredictor_algo]\n",
    "\n",
    "model_names += ['SlopeOne()', \"NormalPredictor()\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Run best models with cold start data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for 5 known ratings per user with SVD...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for SVD: 0.9464617680481648\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for SVD: 0.7420066046025349\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for SVD: 0.8957898783768582\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for SVD: 0.03455584352712358\n",
      "Processing for 10 known ratings per user with SVD...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for SVD: 0.9208013568007083\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for SVD: 0.7199915547661484\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for SVD: 0.8478751386860253\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for SVD: 0.034934546034699435\n",
      "Processing for 20 known ratings per user with SVD...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for SVD: 0.9026553902476236\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for SVD: 0.7038678873360942\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for SVD: 0.8147867535430897\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for SVD: 0.030508507995658324\n",
      "Processing for 5 known ratings per user with SVD++...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for SVD++: 0.9385779055257933\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for SVD++: 0.7343449266201368\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for SVD++: 0.8809284847411851\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for SVD++: 0.03415129411948325\n",
      "Processing for 10 known ratings per user with SVD++...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for SVD++: 0.9149619484249539\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for SVD++: 0.7142117154884996\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for SVD++: 0.837155367065588\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for SVD++: 0.033687621144800624\n",
      "Processing for 20 known ratings per user with SVD++...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for SVD++: 0.8957048126862988\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for SVD++: 0.6971666344174314\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for SVD++: 0.8022871114693976\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for SVD++: 0.036640920994249544\n",
      "Processing for 5 known ratings per user with NMF...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for NMF: 1.0771534429829488\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for NMF: 0.8455061237543896\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for NMF: 1.1602595397300206\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for NMF: 0.006333988536433057\n",
      "Processing for 10 known ratings per user with NMF...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for NMF: 1.0261112165007302\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for NMF: 0.7998902416847926\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for NMF: 1.0529042286286083\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for NMF: 0.007944016850162274\n",
      "Processing for 20 known ratings per user with NMF...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for NMF: 0.9719947603688802\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for NMF: 0.7552320320468238\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for NMF: 0.9447738141845569\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for NMF: 0.004576343927448496\n",
      "Processing for 5 known ratings per user with KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for KNNBasic: 1.1007330136434192\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for KNNBasic: 0.8552813452543082\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for KNNBasic: 1.2116131673245236\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for KNNBasic: 0.006340846629653321\n",
      "Processing for 10 known ratings per user with KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for KNNBasic: 1.0589747378555787\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for KNNBasic: 0.8195244023867239\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for KNNBasic: 1.1214274954162915\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for KNNBasic: 0.0021267511815707854\n",
      "Processing for 20 known ratings per user with KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for KNNBasic: 0.992575721271421\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for KNNBasic: 0.7668001369737925\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for KNNBasic: 0.9852065624574816\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for KNNBasic: 0.0005370510679886555\n",
      "Processing for 5 known ratings per user with KNNWithMeans...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for KNNWithMeans: 1.0813454211232634\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for KNNWithMeans: 0.8378609249327827\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for KNNWithMeans: 1.1693079197842478\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for KNNWithMeans: 0.007500342763962429\n",
      "Processing for 10 known ratings per user with KNNWithMeans...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for KNNWithMeans: 1.015679849824928\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for KNNWithMeans: 0.7890658577110888\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for KNNWithMeans: 1.0316055573403884\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for KNNWithMeans: 0.0027998877311033133\n",
      "Processing for 20 known ratings per user with KNNWithMeans...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for KNNWithMeans: 0.9496924300778921\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for KNNWithMeans: 0.737664846495575\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for KNNWithMeans: 0.9019157117472518\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for KNNWithMeans: 0.001608576617595198\n",
      "Processing for 5 known ratings per user with KNNWithZScore...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for KNNWithZScore: 1.0783219936011192\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for KNNWithZScore: 0.8324517348125667\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for KNNWithZScore: 1.162778321883892\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for KNNWithZScore: 0.006985746535857926\n",
      "Processing for 10 known ratings per user with KNNWithZScore...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for KNNWithZScore: 1.0170681708651232\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for KNNWithZScore: 0.785602295454413\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for KNNWithZScore: 1.0344276641869277\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for KNNWithZScore: 0.002547641260235725\n",
      "Processing for 20 known ratings per user with KNNWithZScore...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for KNNWithZScore: 0.9492489731308372\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for KNNWithZScore: 0.7333375090381237\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for KNNWithZScore: 0.901073612989949\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for KNNWithZScore: 0.0014821706475281523\n",
      "Processing for 5 known ratings per user with KNNBaseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for KNNBaseline: 1.0346919914494768\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for KNNBaseline: 0.8052699701240665\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for KNNBaseline: 1.0705875171696841\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for KNNBaseline: 0.006315214303462898\n",
      "Processing for 10 known ratings per user with KNNBaseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for KNNBaseline: 0.9916321777912603\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for KNNBaseline: 0.7703114485539999\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for KNNBaseline: 0.9833343760310377\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for KNNBaseline: 0.002269041305529883\n",
      "Processing for 20 known ratings per user with KNNBaseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for KNNBaseline: 0.9292730020896568\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for KNNBaseline: 0.7199803836060512\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for KNNBaseline: 0.8635483124127232\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for KNNBaseline: 0.0006236136130020966\n",
      "Processing for 5 known ratings per user with CoClustering...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for CoClustering: 1.0355618781389082\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for CoClustering: 0.8032671171563178\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for CoClustering: 1.0723884034545832\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for CoClustering: 0.003311771393757997\n",
      "Processing for 10 known ratings per user with CoClustering...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for CoClustering: 0.9834859604443829\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for CoClustering: 0.763410441388692\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for CoClustering: 0.9672446343912101\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for CoClustering: 0.0023600428735184287\n",
      "Processing for 20 known ratings per user with CoClustering...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for CoClustering: 0.9447712674644505\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for CoClustering: 0.7333982476199462\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for CoClustering: 0.8925927478263842\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for CoClustering: 0.0021470684017408804\n",
      "Processing for 5 known ratings per user with BaselineOnly...\n",
      "Estimating biases using als...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for BaselineOnly: 0.9470514370810938\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for BaselineOnly: 0.7440255017759718\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for BaselineOnly: 0.896906424477365\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for BaselineOnly: 0.05481039815373199\n",
      "Processing for 10 known ratings per user with BaselineOnly...\n",
      "Estimating biases using als...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for BaselineOnly: 0.9220115333643422\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for BaselineOnly: 0.7224131619523951\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for BaselineOnly: 0.8501052676568654\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for BaselineOnly: 0.057950885571636954\n",
      "Processing for 20 known ratings per user with BaselineOnly...\n",
      "Estimating biases using als...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for BaselineOnly: 0.8993879503771485\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for BaselineOnly: 0.7023701949851718\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for BaselineOnly: 0.8088986852836081\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for BaselineOnly: 0.051978242462700656\n",
      "Processing for 5 known ratings per user with SlopeOne()...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for SlopeOne(): 1.1410760177178234\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for SlopeOne(): 0.8851196359849374\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for SlopeOne(): 1.3020544782107666\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for SlopeOne(): 0.009137374565289834\n",
      "Processing for 10 known ratings per user with SlopeOne()...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for SlopeOne(): 1.0745413014367122\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for SlopeOne(): 0.8351605908042562\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for SlopeOne(): 1.1546390084933031\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for SlopeOne(): 0.003736440541974009\n",
      "Processing for 20 known ratings per user with SlopeOne()...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for SlopeOne(): 0.9802751132599622\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for SlopeOne(): 0.7617426034364156\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for SlopeOne(): 0.9609392976768317\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for SlopeOne(): 0.001460891288681316\n",
      "Processing for 5 known ratings per user with NormalPredictor()...\n",
      "RMSE on filtered cold-start test users (with 5 training ratings each) for NormalPredictor(): 1.4152057306406545\n",
      "MAE on filtered cold-start test users (with 5 training ratings each) for NormalPredictor(): 1.1291033796621353\n",
      "MSE on filtered cold-start test users (with 5 training ratings each) for NormalPredictor(): 2.0028072600381486\n",
      "NDCG@10 on filtered cold-start test users (with 5 training ratings each) for NormalPredictor(): 0.007858451607519143\n",
      "Processing for 10 known ratings per user with NormalPredictor()...\n",
      "RMSE on filtered cold-start test users (with 10 training ratings each) for NormalPredictor(): 1.4132194319148657\n",
      "MAE on filtered cold-start test users (with 10 training ratings each) for NormalPredictor(): 1.1285511690460357\n",
      "MSE on filtered cold-start test users (with 10 training ratings each) for NormalPredictor(): 1.9971891627417757\n",
      "NDCG@10 on filtered cold-start test users (with 10 training ratings each) for NormalPredictor(): 0.00772571777895935\n",
      "Processing for 20 known ratings per user with NormalPredictor()...\n",
      "RMSE on filtered cold-start test users (with 20 training ratings each) for NormalPredictor(): 1.4082594642793897\n",
      "MAE on filtered cold-start test users (with 20 training ratings each) for NormalPredictor(): 1.1244375278602377\n",
      "MSE on filtered cold-start test users (with 20 training ratings each) for NormalPredictor(): 1.9831947187324739\n",
      "NDCG@10 on filtered cold-start test users (with 20 training ratings each) for NormalPredictor(): 0.007375508968917593\n",
      "                Model  Known Ratings      RMSE       MAE       MSE    NDCG@K\n",
      "0                 SVD              5  0.946462  0.742007  0.895790  0.034556\n",
      "1                 SVD             10  0.920801  0.719992  0.847875  0.034935\n",
      "2                 SVD             20  0.902655  0.703868  0.814787  0.030509\n",
      "3               SVD++              5  0.938578  0.734345  0.880928  0.034151\n",
      "4               SVD++             10  0.914962  0.714212  0.837155  0.033688\n",
      "5               SVD++             20  0.895705  0.697167  0.802287  0.036641\n",
      "6                 NMF              5  1.077153  0.845506  1.160260  0.006334\n",
      "7                 NMF             10  1.026111  0.799890  1.052904  0.007944\n",
      "8                 NMF             20  0.971995  0.755232  0.944774  0.004576\n",
      "9            KNNBasic              5  1.100733  0.855281  1.211613  0.006341\n",
      "10           KNNBasic             10  1.058975  0.819524  1.121427  0.002127\n",
      "11           KNNBasic             20  0.992576  0.766800  0.985207  0.000537\n",
      "12       KNNWithMeans              5  1.081345  0.837861  1.169308  0.007500\n",
      "13       KNNWithMeans             10  1.015680  0.789066  1.031606  0.002800\n",
      "14       KNNWithMeans             20  0.949692  0.737665  0.901916  0.001609\n",
      "15      KNNWithZScore              5  1.078322  0.832452  1.162778  0.006986\n",
      "16      KNNWithZScore             10  1.017068  0.785602  1.034428  0.002548\n",
      "17      KNNWithZScore             20  0.949249  0.733338  0.901074  0.001482\n",
      "18        KNNBaseline              5  1.034692  0.805270  1.070588  0.006315\n",
      "19        KNNBaseline             10  0.991632  0.770311  0.983334  0.002269\n",
      "20        KNNBaseline             20  0.929273  0.719980  0.863548  0.000624\n",
      "21       CoClustering              5  1.035562  0.803267  1.072388  0.003312\n",
      "22       CoClustering             10  0.983486  0.763410  0.967245  0.002360\n",
      "23       CoClustering             20  0.944771  0.733398  0.892593  0.002147\n",
      "24       BaselineOnly              5  0.947051  0.744026  0.896906  0.054810\n",
      "25       BaselineOnly             10  0.922012  0.722413  0.850105  0.057951\n",
      "26       BaselineOnly             20  0.899388  0.702370  0.808899  0.051978\n",
      "27         SlopeOne()              5  1.141076  0.885120  1.302054  0.009137\n",
      "28         SlopeOne()             10  1.074541  0.835161  1.154639  0.003736\n",
      "29         SlopeOne()             20  0.980275  0.761743  0.960939  0.001461\n",
      "30  NormalPredictor()              5  1.415206  1.129103  2.002807  0.007858\n",
      "31  NormalPredictor()             10  1.413219  1.128551  1.997189  0.007726\n",
      "32  NormalPredictor()             20  1.408259  1.124438  1.983195  0.007376\n"
     ]
    }
   ],
   "source": [
    "final_results_df = run_cold_start_models(models, model_names, train_df, test_df, eligible_users, known_ratings_list)\n",
    "print(final_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.to_csv('final_results_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
