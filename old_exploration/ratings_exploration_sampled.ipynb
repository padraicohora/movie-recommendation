{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbbe5df-0d97-4d8e-aca7-6fcf4ccf9ce0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# conda activate movie-recommender          # activate environment in terminal         \n",
    "# jupyter notebook                     # start server + kernel inside my-conda-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31931e15-7727-4a29-9dd3-4ab6834df4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:16:21.494Z",
     "start_time": "2024-09-27T14:16:16.576558Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "chunksize=100000\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d008217b9b3c276",
   "metadata": {},
   "source": [
    "Load each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cd5f2b64455ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:25:07.714629Z",
     "start_time": "2024-09-27T14:25:04.451566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1        2     3.5  1112486027\n",
      "1       1       29     3.5  1112484676\n",
      "2       1       32     3.5  1112484819\n",
      "3       1       47     3.5  1112484727\n",
      "4       1       50     3.5  1112484580\n",
      "5       1      112     3.5  1094785740\n",
      "6       1      151     4.0  1094785734\n",
      "7       1      223     4.0  1112485573\n",
      "8       1      253     4.0  1112484940\n",
      "9       1      260     4.0  1112484826\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 610.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ratings_1 = pd.read_csv('../ml-20m/ratings.csv')\n",
    "print(ratings_1.head(10))\n",
    "print(ratings_1.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d740c1a7535622",
   "metadata": {},
   "source": [
    "I notice the types are not being imported correctly. the ids should be strings, as they are not numbers. The timestamp could be converted to a Panda datetime object. This can all be achieved using the read_csv arguments. I  am also setting the chunk size to 500,000 so my computer RAM won't get full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c933657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000026 entries, 4913857 to 16845772\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 76.3 MB\n",
      "None\n",
      "             userId       movieId        rating     timestamp\n",
      "count  2.000026e+06  2.000026e+06  2.000026e+06  2.000026e+06\n",
      "mean   6.904959e+04  9.034708e+03  3.527050e+00  1.101028e+09\n",
      "std    4.003792e+04  1.975883e+04  1.051778e+00  1.621847e+08\n",
      "min    1.000000e+00  1.000000e+00  5.000000e-01  7.896520e+08\n",
      "25%    3.438100e+04  9.030000e+02  3.000000e+00  9.669110e+08\n",
      "50%    6.918000e+04  2.171000e+03  4.000000e+00  1.103701e+09\n",
      "75%    1.036410e+05  4.776000e+03  4.000000e+00  1.225726e+09\n",
      "max    1.384930e+05  1.311760e+05  5.000000e+00  1.427782e+09\n"
     ]
    }
   ],
   "source": [
    "samples = ratings_1.sample(frac=0.1, random_state=7)\n",
    "\n",
    "print(samples.info())\n",
    "print(samples.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7f51d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./samples/sample_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce3710",
   "metadata": {},
   "source": [
    "I noticed the timestamp is not being imported correctly. It should be a full date, but instead it was imported as milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c013d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/xtgthnr12lz2b2j6l0pqj7zm0459s6/T/ipykernel_12532/3003964684.py:6: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  for index, chunk in enumerate(pd.read_csv('../ml-20m/ratings.csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 loaded\n",
      "Chunk 1 loaded\n",
      "Chunk 2 loaded\n",
      "Chunk 3 loaded\n",
      "Chunk 4 loaded\n",
      "Chunk 5 loaded\n",
      "Chunk 6 loaded\n",
      "Chunk 7 loaded\n",
      "Chunk 8 loaded\n",
      "Chunk 9 loaded\n",
      "Chunk 10 loaded\n",
      "Chunk 11 loaded\n",
      "Chunk 12 loaded\n",
      "Chunk 13 loaded\n",
      "Chunk 14 loaded\n",
      "Chunk 15 loaded\n",
      "Chunk 16 loaded\n",
      "Chunk 17 loaded\n",
      "Chunk 18 loaded\n",
      "Chunk 19 loaded\n",
      "Chunk 20 loaded\n",
      "Chunk 21 loaded\n",
      "Chunk 22 loaded\n",
      "Chunk 23 loaded\n",
      "Chunk 24 loaded\n",
      "Chunk 25 loaded\n",
      "Chunk 26 loaded\n",
      "Chunk 27 loaded\n",
      "Chunk 28 loaded\n",
      "Chunk 29 loaded\n",
      "Chunk 30 loaded\n",
      "Chunk 31 loaded\n",
      "Chunk 32 loaded\n",
      "Chunk 33 loaded\n",
      "Chunk 34 loaded\n",
      "Chunk 35 loaded\n",
      "Chunk 36 loaded\n",
      "Chunk 37 loaded\n",
      "Chunk 38 loaded\n",
      "Chunk 39 loaded\n",
      "Chunk 40 loaded\n",
      "Chunk 41 loaded\n",
      "Chunk 42 loaded\n",
      "Chunk 43 loaded\n",
      "Chunk 44 loaded\n",
      "Chunk 45 loaded\n",
      "Chunk 46 loaded\n",
      "Chunk 47 loaded\n",
      "Chunk 48 loaded\n",
      "Chunk 49 loaded\n",
      "Chunk 50 loaded\n",
      "Chunk 51 loaded\n",
      "Chunk 52 loaded\n",
      "Chunk 53 loaded\n",
      "Chunk 54 loaded\n",
      "Chunk 55 loaded\n",
      "Chunk 56 loaded\n",
      "Chunk 57 loaded\n",
      "Chunk 58 loaded\n",
      "Chunk 59 loaded\n",
      "Chunk 60 loaded\n",
      "Chunk 61 loaded\n",
      "Chunk 62 loaded\n",
      "Chunk 63 loaded\n",
      "Chunk 64 loaded\n",
      "Chunk 65 loaded\n",
      "Chunk 66 loaded\n",
      "Chunk 67 loaded\n",
      "Chunk 68 loaded\n",
      "Chunk 69 loaded\n",
      "Chunk 70 loaded\n",
      "Chunk 71 loaded\n",
      "Chunk 72 loaded\n",
      "Chunk 73 loaded\n",
      "Chunk 74 loaded\n",
      "Chunk 75 loaded\n",
      "Chunk 76 loaded\n",
      "Chunk 77 loaded\n",
      "Chunk 78 loaded\n",
      "Chunk 79 loaded\n",
      "Chunk 80 loaded\n",
      "Chunk 81 loaded\n",
      "Chunk 82 loaded\n",
      "Chunk 83 loaded\n",
      "Chunk 84 loaded\n",
      "Chunk 85 loaded\n",
      "Chunk 86 loaded\n",
      "Chunk 87 loaded\n",
      "Chunk 88 loaded\n",
      "Chunk 89 loaded\n",
      "Chunk 90 loaded\n",
      "Chunk 91 loaded\n",
      "Chunk 92 loaded\n",
      "Chunk 93 loaded\n",
      "Chunk 94 loaded\n",
      "Chunk 95 loaded\n",
      "Chunk 96 loaded\n",
      "Chunk 97 loaded\n",
      "Chunk 98 loaded\n",
      "Chunk 99 loaded\n",
      "Chunk 100 loaded\n",
      "Chunk 101 loaded\n",
      "Chunk 102 loaded\n",
      "Chunk 103 loaded\n",
      "Chunk 104 loaded\n",
      "Chunk 105 loaded\n",
      "Chunk 106 loaded\n",
      "Chunk 107 loaded\n",
      "Chunk 108 loaded\n",
      "Chunk 109 loaded\n",
      "Chunk 110 loaded\n",
      "Chunk 111 loaded\n",
      "Chunk 112 loaded\n",
      "Chunk 113 loaded\n",
      "Chunk 114 loaded\n",
      "Chunk 115 loaded\n",
      "Chunk 116 loaded\n",
      "Chunk 117 loaded\n",
      "Chunk 118 loaded\n",
      "Chunk 119 loaded\n",
      "Chunk 120 loaded\n",
      "Chunk 121 loaded\n",
      "Chunk 122 loaded\n",
      "Chunk 123 loaded\n",
      "Chunk 124 loaded\n",
      "Chunk 125 loaded\n",
      "Chunk 126 loaded\n",
      "Chunk 127 loaded\n",
      "Chunk 128 loaded\n",
      "Chunk 129 loaded\n",
      "Chunk 130 loaded\n",
      "Chunk 131 loaded\n",
      "Chunk 132 loaded\n",
      "Chunk 133 loaded\n",
      "Chunk 134 loaded\n",
      "Chunk 135 loaded\n",
      "Chunk 136 loaded\n",
      "Chunk 137 loaded\n",
      "Chunk 138 loaded\n",
      "Chunk 139 loaded\n",
      "Chunk 140 loaded\n",
      "Chunk 141 loaded\n",
      "Chunk 142 loaded\n",
      "Chunk 143 loaded\n",
      "Chunk 144 loaded\n",
      "Chunk 145 loaded\n",
      "Chunk 146 loaded\n",
      "Chunk 147 loaded\n",
      "Chunk 148 loaded\n",
      "Chunk 149 loaded\n",
      "Chunk 150 loaded\n",
      "Chunk 151 loaded\n",
      "Chunk 152 loaded\n",
      "Chunk 153 loaded\n",
      "Chunk 154 loaded\n",
      "Chunk 155 loaded\n",
      "Chunk 156 loaded\n",
      "Chunk 157 loaded\n",
      "Chunk 158 loaded\n",
      "Chunk 159 loaded\n",
      "Chunk 160 loaded\n",
      "Chunk 161 loaded\n",
      "Chunk 162 loaded\n",
      "Chunk 163 loaded\n",
      "Chunk 164 loaded\n",
      "Chunk 165 loaded\n",
      "Chunk 166 loaded\n",
      "Chunk 167 loaded\n",
      "Chunk 168 loaded\n",
      "Chunk 169 loaded\n",
      "Chunk 170 loaded\n",
      "Chunk 171 loaded\n",
      "Chunk 172 loaded\n",
      "Chunk 173 loaded\n",
      "Chunk 174 loaded\n",
      "Chunk 175 loaded\n",
      "Chunk 176 loaded\n",
      "Chunk 177 loaded\n",
      "Chunk 178 loaded\n",
      "Chunk 179 loaded\n",
      "Chunk 180 loaded\n",
      "Chunk 181 loaded\n",
      "Chunk 182 loaded\n",
      "Chunk 183 loaded\n",
      "Chunk 184 loaded\n",
      "Chunk 185 loaded\n",
      "Chunk 186 loaded\n",
      "Chunk 187 loaded\n",
      "Chunk 188 loaded\n",
      "Chunk 189 loaded\n",
      "Chunk 190 loaded\n",
      "Chunk 191 loaded\n",
      "Chunk 192 loaded\n",
      "Chunk 193 loaded\n",
      "Chunk 194 loaded\n",
      "Chunk 195 loaded\n",
      "Chunk 196 loaded\n",
      "Chunk 197 loaded\n",
      "Chunk 198 loaded\n",
      "Chunk 199 loaded\n",
      "Chunk 200 loaded\n",
      "Ratings dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# Custom date parser function\n",
    "date_parser = lambda x: pd.to_datetime(x, unit='s')\n",
    "\n",
    "# ratings\n",
    "ratings = pd.DataFrame()  # initialize an empty dataframe\n",
    "for index, chunk in enumerate(pd.read_csv('./samples/sample_ratings.csv',\n",
    "                         dtype={'userId': str, 'movieId': str, \"rating\": float, 'timestamp': int},\n",
    "                         chunksize=chunksize,\n",
    "                         parse_dates=['timestamp'],\n",
    "                         date_parser=date_parser\n",
    "                         )):\n",
    "    # Perform operations on the chunk\n",
    "    # processed_chunk = chunk[chunk['column_name'] > 0]  # Example operation\n",
    "    ratings = pd.concat([ratings, chunk])\n",
    "    print(f\"Chunk {index} loaded\")\n",
    "print(\"Ratings dataset loaded\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67551823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000026 entries, 4913857 to 16845772\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   userId     object        \n",
      " 1   movieId    object        \n",
      " 2   rating     float64       \n",
      " 3   timestamp  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 76.3+ MB\n",
      "None\n",
      "             rating                      timestamp\n",
      "count  2.000026e+06                        2000026\n",
      "mean   3.527050e+00  2004-11-21 09:03:04.304793088\n",
      "min    5.000000e-01            1995-01-09 11:46:49\n",
      "25%    3.000000e+00     2000-08-22 02:23:52.250000\n",
      "50%    4.000000e+00            2004-12-22 07:43:22\n",
      "75%    4.000000e+00     2008-11-03 15:18:59.500000\n",
      "max    5.000000e+00            2015-03-31 06:00:28\n",
      "std    1.051778e+00                            NaN\n"
     ]
    }
   ],
   "source": [
    "sample_ratings = ratings.sample(frac=0.1, random_state=7)\n",
    "\n",
    "print(sample_ratings.info())\n",
    "print(sample_ratings.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44edb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   userId     object        \n",
      " 1   movieId    object        \n",
      " 2   rating     float64       \n",
      " 3   timestamp  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 610.4+ MB\n",
      "None\n",
      "             rating                      timestamp\n",
      "count  2.000026e+07                       20000263\n",
      "mean   3.525529e+00  2004-11-20 02:32:01.677113984\n",
      "min    5.000000e-01            1995-01-09 11:46:44\n",
      "25%    3.000000e+00            2000-08-20 18:55:45\n",
      "50%    3.500000e+00            2004-12-20 15:18:06\n",
      "75%    4.000000e+00     2008-11-02 16:11:57.500000\n",
      "max    5.000000e+00            2015-03-31 06:40:02\n",
      "std    1.051989e+00                            NaN\n"
     ]
    }
   ],
   "source": [
    "print(ratings.info())\n",
    "print(ratings.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a489f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for rating\n",
    "sns.histplot(data=ratings, x='rating', bins=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
